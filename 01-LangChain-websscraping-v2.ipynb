{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Installations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install langchain openai playwright"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import asyncio\n",
        "import pprint\n",
        "import os\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chat_models.azure_openai import AzureChatOpenAI\n",
        "from langchain.schema import HumanMessage\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain.agents import AgentType\n",
        "from langchain.agents import load_tools\n",
        "from langchain.chains import SimpleSequentialChain, SequentialChain\n",
        "from langchain.memory import SimpleMemory\n",
        "\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv(\"credentials.env\")\n",
        "# Remove either base_url or azure_endpoint depending on your requirements\n",
        "# If you want to use base_url, comment out the azure_endpoint line\n",
        "# If you want to use azure_endpoint, comment out the base_url line"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set API keys\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
        "os.environ[\"OPENAI_API_BASE\"] = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
        "os.environ[\"OPENAI_API_KEY\"] = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
        "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]\n",
        "os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n",
        "MODEL_NAME = \"gpt-4-32k\"\n",
        "\n",
        "# Set this to `azure`\n",
        "OPENAI_API_TYPE = \"azure\"\n",
        "# The API version you want to use: set this to `2023-05-15` for the released version.\n",
        "OPENAI_API_VERSION = os.environ[\"AZURE_OPENAI_API_VERSION\"]\n",
        "# The base URL for your Azure OpenAI resource.  You can find this in the Azure portal under your Azure OpenAI resource.\n",
        "OPENAI_API_BASE = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
        "# The API key for your Azure OpenAI resource.  You can find this in the Azure portal under your Azure OpenAI resource.\n",
        "OPENAI_API_KEY = os.environ[\"AZURE_OPENAI_API_KEY\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"product\"],\n",
        "    template=\"What is a good name for a company that makes {product}?\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Usecase 1: Get predictions from existing model (LLM Primitive)\n",
        "COMPLETION_TOKENS = 500\n",
        "\n",
        "llm = AzureChatOpenAI(\n",
        "    deployment_name=MODEL_NAME, temperature=0.5, max_tokens=COMPLETION_TOKENS\n",
        ")\n",
        "llmchain = LLMChain(llm=llm, prompt=prompt)\n",
        "print(llmchain.run(\"bike model\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# News sites mostly have <span> tags to scrape\n",
        "cnn_url = \"https://www.cnn.com\"\n",
        "wsj_url = \"https://www.wsj.com\"\n",
        "nyt_url = \"https://www.nytimes.com/ca/\"\n",
        "ecommerce_url = \"https://appsumo.com\"\n",
        "amazon_url = \"https://www.amazon.ca/s?k=computers&crid=1LUXGQOD2ULFD&sprefix=%2Caps%2C94&ref=nb_sb_ss_recent_1_0_recent\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "urls = [cnn_url, wsj_url, nyt_url, ecommerce_url, amazon_url]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-6' coro=<Connection.run() done, defined at c:\\00-Project\\Repos\\MyDvlp\\AI-Samples\\langchain-openai-web-scrapper\\.conda\\Lib\\site-packages\\playwright\\_impl\\_connection.py:268> exception=NotImplementedError()>\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\aykeba\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3548, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"C:\\Users\\aykeba\\AppData\\Local\\Temp\\ipykernel_10376\\3468047147.py\", line 28, in <module>\n",
            "    asyncio.run(scrape_with_playwright(url=wsj_url, schema=SchemaNewsWebsites))\n",
            "  File \"C:\\Users\\aykeba\\AppData\\Roaming\\Python\\Python311\\site-packages\\nest_asyncio.py\", line 31, in run\n",
            "    return loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\aykeba\\AppData\\Roaming\\Python\\Python311\\site-packages\\nest_asyncio.py\", line 99, in run_until_complete\n",
            "    return f.result()\n",
            "           ^^^^^^^^^^\n",
            "  File \"c:\\00-Project\\Repos\\MyDvlp\\AI-Samples\\langchain-openai-web-scrapper\\.conda\\Lib\\asyncio\\futures.py\", line 203, in result\n",
            "    raise self._exception.with_traceback(self._exception_tb)\n",
            "  File \"c:\\00-Project\\Repos\\MyDvlp\\AI-Samples\\langchain-openai-web-scrapper\\.conda\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\aykeba\\AppData\\Local\\Temp\\ipykernel_10376\\3468047147.py\", line 19, in scrape_with_playwright\n",
            "    html_content = await ascrape_playwright(url)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\00-Project\\Repos\\MyDvlp\\AI-Samples\\langchain-openai-web-scrapper\\scrape.py\", line 100, in ascrape_playwright\n",
            "    async with async_playwright() as p:\n",
            "  File \"c:\\00-Project\\Repos\\MyDvlp\\AI-Samples\\langchain-openai-web-scrapper\\.conda\\Lib\\site-packages\\playwright\\async_api\\_context_manager.py\", line 47, in __aenter__\n",
            "    playwright = AsyncPlaywright(next(iter(done)).result())\n",
            "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\00-Project\\Repos\\MyDvlp\\AI-Samples\\langchain-openai-web-scrapper\\.conda\\Lib\\asyncio\\futures.py\", line 203, in result\n",
            "    raise self._exception.with_traceback(self._exception_tb)\n",
            "  File \"c:\\00-Project\\Repos\\MyDvlp\\AI-Samples\\langchain-openai-web-scrapper\\.conda\\Lib\\site-packages\\playwright\\_impl\\_transport.py\", line 123, in connect\n",
            "    self._proc = await asyncio.create_subprocess_exec(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\00-Project\\Repos\\MyDvlp\\AI-Samples\\langchain-openai-web-scrapper\\.conda\\Lib\\asyncio\\subprocess.py\", line 221, in create_subprocess_exec\n",
            "    transport, protocol = await loop.subprocess_exec(\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\00-Project\\Repos\\MyDvlp\\AI-Samples\\langchain-openai-web-scrapper\\.conda\\Lib\\asyncio\\base_events.py\", line 1694, in subprocess_exec\n",
            "    transport = await self._make_subprocess_transport(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\00-Project\\Repos\\MyDvlp\\AI-Samples\\langchain-openai-web-scrapper\\.conda\\Lib\\asyncio\\base_events.py\", line 502, in _make_subprocess_transport\n",
            "    raise NotImplementedError\n",
            "NotImplementedError\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Started scraping...\n"
          ]
        },
        {
          "ename": "NotImplementedError",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32mc:\\00-Project\\Repos\\MyDvlp\\AI-Samples\\langchain-openai-web-scrapper\\01-LangChain-websscraping-v2.ipynb Cell 11\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/00-Project/Repos/MyDvlp/AI-Samples/langchain-openai-web-scrapper/01-LangChain-websscraping-v2.ipynb#X30sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     pprint\u001b[39m.\u001b[39mpprint(extracted_content)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/00-Project/Repos/MyDvlp/AI-Samples/langchain-openai-web-scrapper/01-LangChain-websscraping-v2.ipynb#X30sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# Scrape and Extract with LLM\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/00-Project/Repos/MyDvlp/AI-Samples/langchain-openai-web-scrapper/01-LangChain-websscraping-v2.ipynb#X30sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m asyncio\u001b[39m.\u001b[39;49mrun(scrape_with_playwright(url\u001b[39m=\u001b[39;49mwsj_url, schema\u001b[39m=\u001b[39;49mSchemaNewsWebsites))\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\nest_asyncio.py:31\u001b[0m, in \u001b[0;36m_patch_asyncio.<locals>.run\u001b[1;34m(main, debug)\u001b[0m\n\u001b[0;32m     29\u001b[0m task \u001b[39m=\u001b[39m asyncio\u001b[39m.\u001b[39mensure_future(main)\n\u001b[0;32m     30\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 31\u001b[0m     \u001b[39mreturn\u001b[39;00m loop\u001b[39m.\u001b[39;49mrun_until_complete(task)\n\u001b[0;32m     32\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     33\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m task\u001b[39m.\u001b[39mdone():\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\nest_asyncio.py:99\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m f\u001b[39m.\u001b[39mdone():\n\u001b[0;32m     97\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m     98\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mEvent loop stopped before Future completed.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 99\u001b[0m \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39;49mresult()\n",
            "File \u001b[1;32mc:\\00-Project\\Repos\\MyDvlp\\AI-Samples\\langchain-openai-web-scrapper\\.conda\\Lib\\asyncio\\futures.py:203\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__log_traceback \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 203\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\u001b[39m.\u001b[39mwith_traceback(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception_tb)\n\u001b[0;32m    204\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\n",
            "File \u001b[1;32mc:\\00-Project\\Repos\\MyDvlp\\AI-Samples\\langchain-openai-web-scrapper\\.conda\\Lib\\asyncio\\tasks.py:267\u001b[0m, in \u001b[0;36mTask.__step\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    264\u001b[0m     \u001b[39mif\u001b[39;00m exc \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    265\u001b[0m         \u001b[39m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[0;32m    266\u001b[0m         \u001b[39m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m         result \u001b[39m=\u001b[39m coro\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    268\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    269\u001b[0m         result \u001b[39m=\u001b[39m coro\u001b[39m.\u001b[39mthrow(exc)\n",
            "\u001b[1;32mc:\\00-Project\\Repos\\MyDvlp\\AI-Samples\\langchain-openai-web-scrapper\\01-LangChain-websscraping-v2.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/00-Project/Repos/MyDvlp/AI-Samples/langchain-openai-web-scrapper/01-LangChain-websscraping-v2.ipynb#X30sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39mscrape_with_playwright\u001b[39m(url: \u001b[39mstr\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/00-Project/Repos/MyDvlp/AI-Samples/langchain-openai-web-scrapper/01-LangChain-websscraping-v2.ipynb#X30sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     html_content \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m ascrape_playwright(url)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/00-Project/Repos/MyDvlp/AI-Samples/langchain-openai-web-scrapper/01-LangChain-websscraping-v2.ipynb#X30sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mExtracting content with LLM\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/00-Project/Repos/MyDvlp/AI-Samples/langchain-openai-web-scrapper/01-LangChain-websscraping-v2.ipynb#X30sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39m# print(html_content)\u001b[39;00m\n",
            "File \u001b[1;32mc:\\00-Project\\Repos\\MyDvlp\\AI-Samples\\langchain-openai-web-scrapper\\scrape.py:100\u001b[0m, in \u001b[0;36mascrape_playwright\u001b[1;34m(url, tags)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mStarted scraping...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     99\u001b[0m results \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 100\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mwith\u001b[39;00m async_playwright() \u001b[39mas\u001b[39;00m p:\n\u001b[0;32m    101\u001b[0m     browser \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m p\u001b[39m.\u001b[39mchromium\u001b[39m.\u001b[39mlaunch(headless\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    102\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\00-Project\\Repos\\MyDvlp\\AI-Samples\\langchain-openai-web-scrapper\\.conda\\Lib\\site-packages\\playwright\\async_api\\_context_manager.py:47\u001b[0m, in \u001b[0;36mPlaywrightContextManager.__aenter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m playwright_future\u001b[39m.\u001b[39mdone():\n\u001b[0;32m     46\u001b[0m     playwright_future\u001b[39m.\u001b[39mcancel()\n\u001b[1;32m---> 47\u001b[0m playwright \u001b[39m=\u001b[39m AsyncPlaywright(\u001b[39mnext\u001b[39;49m(\u001b[39miter\u001b[39;49m(done))\u001b[39m.\u001b[39;49mresult())\n\u001b[0;32m     48\u001b[0m playwright\u001b[39m.\u001b[39mstop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__aexit__\u001b[39m  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[39mreturn\u001b[39;00m playwright\n",
            "File \u001b[1;32mc:\\00-Project\\Repos\\MyDvlp\\AI-Samples\\langchain-openai-web-scrapper\\.conda\\Lib\\asyncio\\futures.py:203\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__log_traceback \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 203\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\u001b[39m.\u001b[39mwith_traceback(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception_tb)\n\u001b[0;32m    204\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\n",
            "File \u001b[1;32mc:\\00-Project\\Repos\\MyDvlp\\AI-Samples\\langchain-openai-web-scrapper\\.conda\\Lib\\site-packages\\playwright\\_impl\\_transport.py:123\u001b[0m, in \u001b[0;36mPipeTransport.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    120\u001b[0m         startupinfo\u001b[39m.\u001b[39mdwFlags \u001b[39m|\u001b[39m\u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39mSTARTF_USESHOWWINDOW\n\u001b[0;32m    121\u001b[0m         startupinfo\u001b[39m.\u001b[39mwShowWindow \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39mSW_HIDE\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_proc \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m asyncio\u001b[39m.\u001b[39mcreate_subprocess_exec(\n\u001b[0;32m    124\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_driver_executable),\n\u001b[0;32m    125\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mrun-driver\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    126\u001b[0m         stdin\u001b[39m=\u001b[39masyncio\u001b[39m.\u001b[39msubprocess\u001b[39m.\u001b[39mPIPE,\n\u001b[0;32m    127\u001b[0m         stdout\u001b[39m=\u001b[39masyncio\u001b[39m.\u001b[39msubprocess\u001b[39m.\u001b[39mPIPE,\n\u001b[0;32m    128\u001b[0m         stderr\u001b[39m=\u001b[39m_get_stderr_fileno(),\n\u001b[0;32m    129\u001b[0m         limit\u001b[39m=\u001b[39m\u001b[39m32768\u001b[39m,\n\u001b[0;32m    130\u001b[0m         env\u001b[39m=\u001b[39menv,\n\u001b[0;32m    131\u001b[0m         startupinfo\u001b[39m=\u001b[39mstartupinfo,\n\u001b[0;32m    132\u001b[0m     )\n\u001b[0;32m    133\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m    134\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_error_future\u001b[39m.\u001b[39mset_exception(exc)\n",
            "File \u001b[1;32mc:\\00-Project\\Repos\\MyDvlp\\AI-Samples\\langchain-openai-web-scrapper\\.conda\\Lib\\asyncio\\subprocess.py:221\u001b[0m, in \u001b[0;36mcreate_subprocess_exec\u001b[1;34m(program, stdin, stdout, stderr, limit, *args, **kwds)\u001b[0m\n\u001b[0;32m    218\u001b[0m loop \u001b[39m=\u001b[39m events\u001b[39m.\u001b[39mget_running_loop()\n\u001b[0;32m    219\u001b[0m protocol_factory \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m: SubprocessStreamProtocol(limit\u001b[39m=\u001b[39mlimit,\n\u001b[0;32m    220\u001b[0m                                                     loop\u001b[39m=\u001b[39mloop)\n\u001b[1;32m--> 221\u001b[0m transport, protocol \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m loop\u001b[39m.\u001b[39msubprocess_exec(\n\u001b[0;32m    222\u001b[0m     protocol_factory,\n\u001b[0;32m    223\u001b[0m     program, \u001b[39m*\u001b[39margs,\n\u001b[0;32m    224\u001b[0m     stdin\u001b[39m=\u001b[39mstdin, stdout\u001b[39m=\u001b[39mstdout,\n\u001b[0;32m    225\u001b[0m     stderr\u001b[39m=\u001b[39mstderr, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    226\u001b[0m \u001b[39mreturn\u001b[39;00m Process(transport, protocol, loop)\n",
            "File \u001b[1;32mc:\\00-Project\\Repos\\MyDvlp\\AI-Samples\\langchain-openai-web-scrapper\\.conda\\Lib\\asyncio\\base_events.py:1694\u001b[0m, in \u001b[0;36mBaseEventLoop.subprocess_exec\u001b[1;34m(self, protocol_factory, program, stdin, stdout, stderr, universal_newlines, shell, bufsize, encoding, errors, text, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1692\u001b[0m     debug_log \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mexecute program \u001b[39m\u001b[39m{\u001b[39;00mprogram\u001b[39m!r}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m   1693\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_subprocess(debug_log, stdin, stdout, stderr)\n\u001b[1;32m-> 1694\u001b[0m transport \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_subprocess_transport(\n\u001b[0;32m   1695\u001b[0m     protocol, popen_args, \u001b[39mFalse\u001b[39;00m, stdin, stdout, stderr,\n\u001b[0;32m   1696\u001b[0m     bufsize, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1697\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_debug \u001b[39mand\u001b[39;00m debug_log \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1698\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m'\u001b[39m, debug_log, transport)\n",
            "File \u001b[1;32mc:\\00-Project\\Repos\\MyDvlp\\AI-Samples\\langchain-openai-web-scrapper\\.conda\\Lib\\asyncio\\base_events.py:502\u001b[0m, in \u001b[0;36mBaseEventLoop._make_subprocess_transport\u001b[1;34m(self, protocol, args, shell, stdin, stdout, stderr, bufsize, extra, **kwargs)\u001b[0m\n\u001b[0;32m    498\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39m_make_subprocess_transport\u001b[39m(\u001b[39mself\u001b[39m, protocol, args, shell,\n\u001b[0;32m    499\u001b[0m                                      stdin, stdout, stderr, bufsize,\n\u001b[0;32m    500\u001b[0m                                      extra\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    501\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Create subprocess transport.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 502\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m\n",
            "\u001b[1;31mNotImplementedError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import asyncio\n",
        "import pprint\n",
        "\n",
        "from ai_extractor import extract\n",
        "from schemas import SchemaNewsWebsites, ecommerce_schema\n",
        "from scrape import ascrape_playwright\n",
        "\n",
        "token_limit = 8000\n",
        "\n",
        "# News sites mostly have <span> tags to scrape\n",
        "cnn_url = \"https://www.cnn.com\"\n",
        "wsj_url = \"https://www.wsj.com\"\n",
        "nyt_url = \"https://www.nytimes.com/ca/\"\n",
        "ecommerce_url = \"https://appsumo.com\"\n",
        "amazon_url = \"https://www.amazon.ca/s?k=computers&crid=1LUXGQOD2ULFD&sprefix=%2Caps%2C94&ref=nb_sb_ss_recent_1_0_recent\"\n",
        "\n",
        "\n",
        "async def scrape_with_playwright(url: str, **kwargs):\n",
        "    html_content = await ascrape_playwright(url)\n",
        "    print(\"Extracting content with LLM\")\n",
        "    # print(html_content)\n",
        "    html_content_fits_context_window_llm = html_content[:token_limit]\n",
        "    extracted_content = extract(**kwargs, content=html_content_fits_context_window_llm)\n",
        "    pprint.pprint(extracted_content)\n",
        "\n",
        "\n",
        "# Scrape and Extract with LLM\n",
        "asyncio.run(scrape_with_playwright(url=wsj_url, schema=SchemaNewsWebsites))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\00-Project\\Repos\\MyDvlp\\AI-Samples\\langchain-openai-web-scrapper\\.conda\\Lib\\ast.py:50: RuntimeWarning: coroutine 'scrape_playwright' was never awaited\n",
            "  return compile(source, filename, mode, flags,\n",
            "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-2' coro=<Connection.run() done, defined at c:\\00-Project\\Repos\\MyDvlp\\AI-Samples\\langchain-openai-web-scrapper\\.conda\\Lib\\site-packages\\playwright\\_impl\\_connection.py:268> exception=NotImplementedError()>\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\aykeba\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3548, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"C:\\Users\\aykeba\\AppData\\Local\\Temp\\ipykernel_10376\\919281970.py\", line 13, in <module>\n",
            "    loop.run_until_complete(scrape_playwright())\n",
            "  File \"C:\\Users\\aykeba\\AppData\\Roaming\\Python\\Python311\\site-packages\\nest_asyncio.py\", line 99, in run_until_complete\n",
            "    return f.result()\n",
            "           ^^^^^^^^^^\n",
            "  File \"c:\\00-Project\\Repos\\MyDvlp\\AI-Samples\\langchain-openai-web-scrapper\\.conda\\Lib\\asyncio\\futures.py\", line 203, in result\n",
            "    raise self._exception.with_traceback(self._exception_tb)\n",
            "  File \"c:\\00-Project\\Repos\\MyDvlp\\AI-Samples\\langchain-openai-web-scrapper\\.conda\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\aykeba\\AppData\\Local\\Temp\\ipykernel_10376\\919281970.py\", line 7, in scrape_playwright\n",
            "    results = await ascrape_playwright(url)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\00-Project\\Repos\\MyDvlp\\AI-Samples\\langchain-openai-web-scrapper\\scrape.py\", line 100, in ascrape_playwright\n",
            "    async with async_playwright() as p:\n",
            "  File \"c:\\00-Project\\Repos\\MyDvlp\\AI-Samples\\langchain-openai-web-scrapper\\.conda\\Lib\\site-packages\\playwright\\async_api\\_context_manager.py\", line 47, in __aenter__\n",
            "    playwright = AsyncPlaywright(next(iter(done)).result())\n",
            "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\00-Project\\Repos\\MyDvlp\\AI-Samples\\langchain-openai-web-scrapper\\.conda\\Lib\\asyncio\\futures.py\", line 203, in result\n",
            "    raise self._exception.with_traceback(self._exception_tb)\n",
            "  File \"c:\\00-Project\\Repos\\MyDvlp\\AI-Samples\\langchain-openai-web-scrapper\\.conda\\Lib\\site-packages\\playwright\\_impl\\_transport.py\", line 123, in connect\n",
            "    self._proc = await asyncio.create_subprocess_exec(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\00-Project\\Repos\\MyDvlp\\AI-Samples\\langchain-openai-web-scrapper\\.conda\\Lib\\asyncio\\subprocess.py\", line 221, in create_subprocess_exec\n",
            "    transport, protocol = await loop.subprocess_exec(\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\00-Project\\Repos\\MyDvlp\\AI-Samples\\langchain-openai-web-scrapper\\.conda\\Lib\\asyncio\\base_events.py\", line 1694, in subprocess_exec\n",
            "    transport = await self._make_subprocess_transport(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\00-Project\\Repos\\MyDvlp\\AI-Samples\\langchain-openai-web-scrapper\\.conda\\Lib\\asyncio\\base_events.py\", line 502, in _make_subprocess_transport\n",
            "    raise NotImplementedError\n",
            "NotImplementedError\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Started scraping...\n",
            "Unexpected exception formatting exception. Falling back to standard exception\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\aykeba\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3548, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"C:\\Users\\aykeba\\AppData\\Local\\Temp\\ipykernel_10376\\919281970.py\", line 13, in <module>\n",
            "    loop.run_until_complete(scrape_playwright())\n",
            "  File \"C:\\Users\\aykeba\\AppData\\Roaming\\Python\\Python311\\site-packages\\nest_asyncio.py\", line 99, in run_until_complete\n",
            "    return f.result()\n",
            "           ^^^^^^^^^^\n",
            "  File \"c:\\00-Project\\Repos\\MyDvlp\\AI-Samples\\langchain-openai-web-scrapper\\.conda\\Lib\\asyncio\\futures.py\", line 203, in result\n",
            "    raise self._exception.with_traceback(self._exception_tb)\n",
            "  File \"c:\\00-Project\\Repos\\MyDvlp\\AI-Samples\\langchain-openai-web-scrapper\\.conda\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\aykeba\\AppData\\Local\\Temp\\ipykernel_10376\\919281970.py\", line 7, in scrape_playwright\n",
            "    results = await ascrape_playwright(url)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\00-Project\\Repos\\MyDvlp\\AI-Samples\\langchain-openai-web-scrapper\\scrape.py\", line 100, in ascrape_playwright\n",
            "    async with async_playwright() as p:\n",
            "  File \"c:\\00-Project\\Repos\\MyDvlp\\AI-Samples\\langchain-openai-web-scrapper\\.conda\\Lib\\site-packages\\playwright\\async_api\\_context_manager.py\", line 47, in __aenter__\n",
            "    playwright = AsyncPlaywright(next(iter(done)).result())\n",
            "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\00-Project\\Repos\\MyDvlp\\AI-Samples\\langchain-openai-web-scrapper\\.conda\\Lib\\asyncio\\futures.py\", line 203, in result\n",
            "    raise self._exception.with_traceback(self._exception_tb)\n",
            "  File \"c:\\00-Project\\Repos\\MyDvlp\\AI-Samples\\langchain-openai-web-scrapper\\.conda\\Lib\\site-packages\\playwright\\_impl\\_transport.py\", line 123, in connect\n",
            "    self._proc = await asyncio.create_subprocess_exec(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\00-Project\\Repos\\MyDvlp\\AI-Samples\\langchain-openai-web-scrapper\\.conda\\Lib\\asyncio\\subprocess.py\", line 221, in create_subprocess_exec\n",
            "    transport, protocol = await loop.subprocess_exec(\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\00-Project\\Repos\\MyDvlp\\AI-Samples\\langchain-openai-web-scrapper\\.conda\\Lib\\asyncio\\base_events.py\", line 1694, in subprocess_exec\n",
            "    transport = await self._make_subprocess_transport(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\00-Project\\Repos\\MyDvlp\\AI-Samples\\langchain-openai-web-scrapper\\.conda\\Lib\\asyncio\\base_events.py\", line 502, in _make_subprocess_transport\n",
            "    raise NotImplementedError\n",
            "NotImplementedError\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\aykeba\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 2142, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\aykeba\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\aykeba\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1326, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\aykeba\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1173, in structured_traceback\n",
            "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\aykeba\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1063, in format_exception_as_a_whole\n",
            "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\aykeba\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1160, in get_records\n",
            "    res = list(stack_data.FrameInfo.stack_data(etb, options=options))[tb_offset:]\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\aykeba\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\core.py\", line 597, in stack_data\n",
            "    yield from collapse_repeated(\n",
            "  File \"C:\\Users\\aykeba\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\utils.py\", line 83, in collapse_repeated\n",
            "    yield from map(mapper, original_group)\n",
            "  File \"C:\\Users\\aykeba\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\core.py\", line 587, in mapper\n",
            "    return cls(f, options)\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\aykeba\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\core.py\", line 551, in __init__\n",
            "    self.executing = Source.executing(frame_or_tb)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\aykeba\\AppData\\Roaming\\Python\\Python311\\site-packages\\executing\\executing.py\", line 264, in executing\n",
            "    source = cls.for_frame(frame)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\aykeba\\AppData\\Roaming\\Python\\Python311\\site-packages\\executing\\executing.py\", line 183, in for_frame\n",
            "    return cls.for_filename(frame.f_code.co_filename, frame.f_globals or {}, use_cache)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\aykeba\\AppData\\Roaming\\Python\\Python311\\site-packages\\executing\\executing.py\", line 212, in for_filename\n",
            "    return cls._for_filename_and_lines(filename, tuple(lines))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\aykeba\\AppData\\Roaming\\Python\\Python311\\site-packages\\executing\\executing.py\", line 223, in _for_filename_and_lines\n",
            "    result = source_cache[(filename, lines)] = cls(filename, lines)\n",
            "                                               ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\aykeba\\AppData\\Roaming\\Python\\Python311\\site-packages\\executing\\executing.py\", line 163, in __init__\n",
            "    self.tree = ast.parse(self.text, filename=filename)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\00-Project\\Repos\\MyDvlp\\AI-Samples\\langchain-openai-web-scrapper\\.conda\\Lib\\ast.py\", line 50, in parse\n",
            "    return compile(source, filename, mode, flags,\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "SystemError: AST constructor recursion depth mismatch (before=129, after=184)\n"
          ]
        }
      ],
      "source": [
        "kwargs = {}  # Define the kwargs variable\n",
        "await scrape_with_playwright(urls[0], **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'scrape_with_playwright' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\00-Project\\Repos\\MyDvlp\\AI-Samples\\langchain-openai-web-scrapper\\01-LangChain-websscraping-v2.ipynb Cell 13\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/00-Project/Repos/MyDvlp/AI-Samples/langchain-openai-web-scrapper/01-LangChain-websscraping-v2.ipynb#X32sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m nest_asyncio\u001b[39m.\u001b[39mapply()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/00-Project/Repos/MyDvlp/AI-Samples/langchain-openai-web-scrapper/01-LangChain-websscraping-v2.ipynb#X32sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m loop \u001b[39m=\u001b[39m asyncio\u001b[39m.\u001b[39mget_event_loop()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/00-Project/Repos/MyDvlp/AI-Samples/langchain-openai-web-scrapper/01-LangChain-websscraping-v2.ipynb#X32sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m loop\u001b[39m.\u001b[39mrun_until_complete(\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/00-Project/Repos/MyDvlp/AI-Samples/langchain-openai-web-scrapper/01-LangChain-websscraping-v2.ipynb#X32sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     scrape_with_playwright(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/00-Project/Repos/MyDvlp/AI-Samples/langchain-openai-web-scrapper/01-LangChain-websscraping-v2.ipynb#X32sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         url\u001b[39m=\u001b[39mecommerce_url,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/00-Project/Repos/MyDvlp/AI-Samples/langchain-openai-web-scrapper/01-LangChain-websscraping-v2.ipynb#X32sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         \u001b[39m# schema_pydantic=SchemaNewsWebsites\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/00-Project/Repos/MyDvlp/AI-Samples/langchain-openai-web-scrapper/01-LangChain-websscraping-v2.ipynb#X32sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         schema\u001b[39m=\u001b[39mecommerce_schema,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/00-Project/Repos/MyDvlp/AI-Samples/langchain-openai-web-scrapper/01-LangChain-websscraping-v2.ipynb#X32sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/00-Project/Repos/MyDvlp/AI-Samples/langchain-openai-web-scrapper/01-LangChain-websscraping-v2.ipynb#X32sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m )\n",
            "\u001b[1;31mNameError\u001b[0m: name 'scrape_with_playwright' is not defined"
          ]
        }
      ],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "py311_conda",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "orig_nbformat": 4,
    "polyglot_notebook": {
      "kernelInfo": {
        "defaultKernelName": "csharp",
        "items": [
          {
            "aliases": [],
            "name": "csharp"
          }
        ]
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
